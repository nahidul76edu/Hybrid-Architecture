{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C-SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRkTu3CZN8Tg"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers import merge, Input\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import keras\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC5v1N02N9k6"
      },
      "source": [
        "training_data = np.load('/content/drive/MyDrive/Imotive_AEP_data/Music_S7.npy', allow_pickle=True)\n",
        "x_train=np.array([i[0] for i in training_data])\n",
        "y_train=np.array([i[1] for i in training_data])\n",
        "x_train=x_train/255\n",
        "\n",
        "testing_data = np.load('/content/drive/MyDrive/Imotive_AEP_data/Silent_S7.npy', allow_pickle=True)\n",
        "x_test=np.array([i[0] for i in testing_data])\n",
        "y_test=np.array([i[1] for i in testing_data])\n",
        "x_test=x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icRsYPCgN_lp"
      },
      "source": [
        "y_train_1=[]\n",
        "for i in y_train:\n",
        "  if i[0]==0 and i[1]==1:\n",
        "    y_train_1.append(0)\n",
        "\n",
        "y_test_1=[]\n",
        "for i in y_test:\n",
        "  if i[0]==1 and i[1]==0:\n",
        "    y_test_1.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu_ewEGAOBpp"
      },
      "source": [
        "X = np.concatenate((x_train, x_test))\n",
        "Y = np.concatenate((y_train_1, y_test_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDsL07lTODWp"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.30, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpzIr5ktOHjw"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (5, 5), padding='same', input_shape=(224, 224, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), name='feature_layer1'))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), name='feature_layer2'))\n",
        "#model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "#model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(3, 3), name='feature_layer3'))\n",
        "#model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "new_model2 = Model(inputs=model.input,outputs=model.get_layer('feature_layer2').output)\n",
        "\n",
        "train_x = new_model2.predict(x_train)\n",
        "test_x = new_model2.predict(x_test)\n",
        "\n",
        "x_train1 = train_x.reshape(train_x.shape[0], train_x.shape[1]*train_x.shape[2]*train_x.shape[3])\n",
        "x_test1 = test_x.reshape(test_x.shape[0], test_x.shape[1]*test_x.shape[2]*test_x.shape[3])\n",
        "\n",
        "classifier = SVC(kernel = 'rbf', gamma='scale', random_state = 0, max_iter=-1,  tol=0.0001,degree=3, verbose=False, class_weight=None, C=500.0)\n",
        "\n",
        "classifier.fit(x_train1, y_train)\n",
        "\n",
        "Y_Pred = classifier.predict(x_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaZTnVacOJ-g"
      },
      "source": [
        "cm = confusion_matrix(y_test, Y_Pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPYJGp1dONQ5"
      },
      "source": [
        "import sklearn\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, Y_Pred))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, Y_Pred))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, Y_Pred))\n",
        "print(\"F1_Score:\", metrics.f1_score(y_test, Y_Pred))\n",
        "print(\"Cohen_Kappa_Score:\",sklearn.metrics.cohen_kappa_score(y_test, Y_Pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}